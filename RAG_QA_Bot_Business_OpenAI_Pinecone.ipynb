{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "544b493b",
   "metadata": {},
   "source": [
    "# üìò Task 1: RAG QA Bot for Business\n",
    "Develop a Retrieval-Augmented Generation (RAG) QA bot using OpenAI and Pinecone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae31f2a5",
   "metadata": {},
   "source": [
    "## üîß SECTION 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca79a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai langchain pinecone-client python-dotenv unstructured pdfminer.six faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f11077",
   "metadata": {},
   "source": [
    "## üì¶ SECTION 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c27e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5e61e",
   "metadata": {},
   "source": [
    "## üîê SECTION 3: API Key Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your actual API keys\n",
    "OPENAI_API_KEY = \"sk-proj-...\"  # Replace with your key\n",
    "PINECONE_API_KEY = \"pcsk_...\"   # Replace with your key\n",
    "PINECONE_ENVIRONMENT = \"gcp-starter\"\n",
    "PINECONE_INDEX_NAME = \"business-index\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7cea8",
   "metadata": {},
   "source": [
    "## üìÑ SECTION 4: Upload & Load Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded = files.upload()\n",
    "file_name = list(uploaded.keys())[0]\n",
    "\n",
    "doc_loader = UnstructuredFileLoader(file_name)\n",
    "raw_docs = doc_loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = splitter.split_documents(raw_docs)\n",
    "print(f\"Loaded {len(documents)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202a34a0",
   "metadata": {},
   "source": [
    "## üß† SECTION 5: Embed Documents & Upload to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Pinecone.from_documents(documents, embeddings, index_name=PINECONE_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebbab83",
   "metadata": {},
   "source": [
    "## üîç SECTION 6: Query Answering using RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77656bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13897a2",
   "metadata": {},
   "source": [
    "## üß™ SECTION 7: Test the QA Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What services does our business offer?\"\n",
    "result = qa_chain.invoke(query)\n",
    "\n",
    "print(\"\\nAnswer:\\n\", result['result'])\n",
    "print(\"\\nSource Document Snippets:\\n\")\n",
    "for doc in result['source_documents']:\n",
    "    print(doc.page_content[:300], \"...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fdd9c1",
   "metadata": {},
   "source": [
    "## ‚úÖ Task Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RAG QA Bot setup complete! Test with more queries.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "generated",
   "name": "RAG_QA_Bot_Business_OpenAI_Pinecone",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
